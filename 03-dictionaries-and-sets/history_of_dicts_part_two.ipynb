{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A look on evolution of Python dictionaries. \n",
    "It is extra-curricular to the book material, but fits with the chapter spirit. These details provide a fascinating insight into the implementation techniques used in CPython. Please look at Raymond Hattinger talk on same subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "keys = 'guido sarah barry rachel tim'.split()\n",
    "values1 = 'blue orange green yellow red'.split()\n",
    "values2 = 'austin dallas tuscon reno portland'.split()\n",
    "values3 = 'apple banana orange pear peach'.split()\n",
    "hashes = list(map(abs, map(hash, keys)))\n",
    "entries = list(zip(hashes, keys, values1))\n",
    "comb_entries = list(zip(hashes, keys, values1, values2, values3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8664339436170913282, 'guido', 'blue', 'austin', 'apple'),\n",
      " (1459880389773299350, 'sarah', 'orange', 'dallas', 'banana'),\n",
      " (1328909732855774812, 'barry', 'green', 'tuscon', 'orange'),\n",
      " (3429570129038273801, 'rachel', 'yellow', 'reno', 'pear'),\n",
      " (3209648040892702255, 'tim', 'red', 'portland', 'peach')]\n"
     ]
    }
   ],
   "source": [
    "pprint(comb_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how databases store their entries. There are four columns primary_key, colour, city, fruit. It was a very space efficient way of storing data and memory in the 60s was a precious resource. Unless some indexing technique is implemented, this database will be characterised by linear search, which is going to be quite slow for larger data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('guido', 'blue', 'austin', 'apple'),\n",
      " ('sarah', 'orange', 'dallas', 'banana'),\n",
      " ('barry', 'green', 'tuscon', 'orange'),\n",
      " ('rachel', 'yellow', 'reno', 'pear'),\n",
      " ('tim', 'red', 'portland', 'peach')]\n"
     ]
    }
   ],
   "source": [
    "def database_linear_search():\n",
    "    pprint(list(zip(keys, values1, values2, values3)))\n",
    "\n",
    "database_linear_search()\n",
    "# Things were stored as flat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## How Lisp would do it\n",
    "\n",
    "If we wish to improve performance we can store it the way LISP used to as a lists of key, pairs. The association lists occupy more memory as every key is stored three times instead of once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('guido', 'blue'),\n",
      "  ('sarah', 'orange'),\n",
      "  ('barry', 'green'),\n",
      "  ('rachel', 'yellow'),\n",
      "  ('tim', 'red')],\n",
      " [('guido', 'austin'),\n",
      "  ('sarah', 'dallas'),\n",
      "  ('barry', 'tuscon'),\n",
      "  ('rachel', 'reno'),\n",
      "  ('tim', 'portland')],\n",
      " [('guido', 'apple'),\n",
      "  ('sarah', 'banana'),\n",
      "  ('barry', 'orange'),\n",
      "  ('rachel', 'pear'),\n",
      "  ('tim', 'peach')]]\n"
     ]
    }
   ],
   "source": [
    "def association_lists():\n",
    "    pprint([\n",
    "        list(zip(keys, values1)),\n",
    "        list(zip(keys, values2)),\n",
    "        list(zip(keys, values3)),\n",
    "    ])\n",
    "    \n",
    "association_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Seperate Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(8664339436170913282, 'guido', 'blue'),\n",
      "  (1459880389773299350, 'sarah', 'orange'),\n",
      "  (1328909732855774812, 'barry', 'green')],\n",
      " [(3429570129038273801, 'rachel', 'yellow'),\n",
      "  (3209648040892702255, 'tim', 'red')]]\n"
     ]
    }
   ],
   "source": [
    "def separate_chaining(n):\n",
    "    buckets = [[] for _ in range(n)] # We initialize n empty buckets\n",
    "    for pair in entries:\n",
    "        h, key, value = pair\n",
    "        i = h % n # Will choose a bucket by modulo dividing hash\n",
    "        buckets[i].append(pair) \n",
    "    pprint(buckets)\n",
    "    \n",
    "separate_chaining(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives about 25% improved lookup. Some of the keys like `'sarah'` are found really fast, while with others we still need to go through a list of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1328909732855774812, 'barry', 'green')],\n",
      " [(3429570129038273801, 'rachel', 'yellow')],\n",
      " [(8664339436170913282, 'guido', 'blue'),\n",
      "  (1459880389773299350, 'sarah', 'orange')],\n",
      " [(3209648040892702255, 'tim', 'red')]]\n"
     ]
    }
   ],
   "source": [
    "separate_chaining(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(3429570129038273801, 'rachel', 'yellow'),\n",
      "  (3209648040892702255, 'tim', 'red')],\n",
      " [(1328909732855774812, 'barry', 'green')],\n",
      " [],\n",
      " [(1459880389773299350, 'sarah', 'orange')],\n",
      " [(8664339436170913282, 'guido', 'blue')],\n",
      " [],\n",
      " []]\n"
     ]
    }
   ],
   "source": [
    "separate_chaining(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "If we throw more memory at this problem by making more buckets we improve the performance. With 7 separate buckets everyone gets found in just one probe. We have exchanged linear time for constant lookup. However, we need to initialize several lists, which need to be overallocated to allow room to grow, while some of them might even be empty. To avoid overallocation we can one big table...\n",
    "\n",
    "## Open Addressing\n",
    "Instead of using multiple lists will just employ one big list and nudge the values around it if they would like to occupy same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def open_addressing_linear(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            print(f'{key!r} collided with {table[i][0]!r}')\n",
    "            i = (i + 1) % n  # This is nudge the key further in list\n",
    "        table[i] = (key, value)\n",
    "    print('\\nOpen Addressing Table:\\n')\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open Addressing Table:\n",
      "\n",
      "[None,\n",
      " ('rachel', 'yellow'),\n",
      " ('guido', 'blue'),\n",
      " None,\n",
      " ('barry', 'green'),\n",
      " None,\n",
      " ('sarah', 'orange'),\n",
      " ('tim', 'red')]\n"
     ]
    }
   ],
   "source": [
    "open_addressing_linear(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Rachel wanted the same spot as Barry and Sarah. Sometimes this would lead to a catastrophic linear pile-up in which all of a sudden your code would be dog slow. (These pile-ups are 1972)\n",
    "\n",
    "We can improve the behaviour of open addressing if we fall on random number generator rather than a slight nudge. specifically we should consider congruential number generator `i = 5 * i + 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def open_addressing_multihash(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        perturb = h\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            print(f'{key!r} collided with {table[i][0]!r}')\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = (key, value)\n",
    "    print('\\nOpen Addressing Table Multihash:\\n')\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Open Addressing Table Multihash:\n",
      "\n",
      "[None,\n",
      " ('rachel', 'yellow'),\n",
      " ('guido', 'blue'),\n",
      " None,\n",
      " ('barry', 'green'),\n",
      " None,\n",
      " ('sarah', 'orange'),\n",
      " ('tim', 'red')]\n"
     ]
    }
   ],
   "source": [
    "open_addressing_multihash(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Performance slowed down but we avoid the catastrophic pileup\n",
    "\n",
    "If we use more space we avoid collisions which speeds up performance\n",
    "but use more memory. This implementation was in Python for quite a\n",
    "while with some size changes.\n",
    "\n",
    "We can save memory if we start using a separate list to store the positions of keys in the primary table.\n",
    "\n",
    "## Compact Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compact_and_ordered(n):\n",
    "    table = [None] * n\n",
    "    for pos, entry, in enumerate(entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(entries)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8664339436170913282, 'guido', 'blue'),\n",
      " (1459880389773299350, 'sarah', 'orange'),\n",
      " (1328909732855774812, 'barry', 'green'),\n",
      " (3429570129038273801, 'rachel', 'yellow'),\n",
      " (3209648040892702255, 'tim', 'red')]\n",
      "[None, 3, 0, None, 2, None, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "compact_and_ordered(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This together with the key-sharing dict makes current 3.6 CPython dict implementation. Key sharing dicts share keys among different instances of the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def shared_and_compact(n):\n",
    "    'Compact, ordered, and shared'\n",
    "    table = [None] * n\n",
    "    for pos, entry in enumerate(comb_entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(comb_entries)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8664339436170913282, 'guido', 'blue', 'austin', 'apple'),\n",
      " (1459880389773299350, 'sarah', 'orange', 'dallas', 'banana'),\n",
      " (1328909732855774812, 'barry', 'green', 'tuscon', 'orange'),\n",
      " (3429570129038273801, 'rachel', 'yellow', 'reno', 'pear'),\n",
      " (3209648040892702255, 'tim', 'red', 'portland', 'peach')]\n",
      "[None, 3, 0, None, 2, None, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "shared_and_compact(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What is particularly elegant is that we can now make these dicts a lot sparser while incurring a very little penalty in terms of memory consumed. The additional sparsity costs only 8 bytes and avoids all of the collisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8664339436170913282, 'guido', 'blue', 'austin', 'apple'),\n",
      " (1459880389773299350, 'sarah', 'orange', 'dallas', 'banana'),\n",
      " (1328909732855774812, 'barry', 'green', 'tuscon', 'orange'),\n",
      " (3429570129038273801, 'rachel', 'yellow', 'reno', 'pear'),\n",
      " (3209648040892702255, 'tim', 'red', 'portland', 'peach')]\n",
      "[None,\n",
      " None,\n",
      " 0,\n",
      " None,\n",
      " None,\n",
      " None,\n",
      " 1,\n",
      " None,\n",
      " None,\n",
      " 3,\n",
      " None,\n",
      " None,\n",
      " 2,\n",
      " None,\n",
      " None,\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "shared_and_compact(16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
