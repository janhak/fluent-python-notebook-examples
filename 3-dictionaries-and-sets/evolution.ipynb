{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "keys = 'guido sarah barry rachel tim'.split()\n",
    "values1 = 'blue orange green yellow red'.split()\n",
    "values2 = 'austin dallas tuscon reno portland'.split()\n",
    "values3 = 'apple banana orange pear peach'.split()\n",
    "hashes = list(map(abs, map(hash, keys)))\n",
    "entries = list(zip(hashes, keys, values1))\n",
    "comb_entries = list(zip(hashes, keys, values1, values2, values3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6263957734076381623, 'guido', 'blue', 'austin', 'apple'),\n (4670100726627187108, 'sarah', 'orange', 'dallas', 'banana'),\n (4505871006362405169, 'barry', 'green', 'tuscon', 'orange'),\n (8301609630502316535, 'rachel', 'yellow', 'reno', 'pear'),\n (6421035295685486569, 'tim', 'red', 'portland', 'peach')]\n"
     ]
    }
   ],
   "source": [
    "pprint(comb_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would database store this entries welcome to 60s\n",
    "# 4 columns primary_key, color, city, fruit\n",
    "# They stored it like that because memory was precious\n",
    "\n",
    "\n",
    "def database_linear_search():\n",
    "    pprint(list(zip(keys, values1, values2, values3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('guido', 'blue', 'austin', 'apple'),\n ('sarah', 'orange', 'dallas', 'banana'),\n ('barry', 'green', 'tuscon', 'orange'),\n ('rachel', 'yellow', 'reno', 'pear'),\n ('tim', 'red', 'portland', 'peach')]\n"
     ]
    }
   ],
   "source": [
    "database_linear_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things were stored as flat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('guido', 'blue'),\n  ('sarah', 'orange'),\n  ('barry', 'green'),\n  ('rachel', 'yellow'),\n  ('tim', 'red')],\n [('guido', 'austin'),\n  ('sarah', 'dallas'),\n  ('barry', 'tuscon'),\n  ('rachel', 'reno'),\n  ('tim', 'portland')],\n [('guido', 'apple'),\n  ('sarah', 'banana'),\n  ('barry', 'orange'),\n  ('rachel', 'pear'),\n  ('tim', 'peach')]]\n"
     ]
    }
   ],
   "source": [
    "# How LISP Would Do It \n",
    "# Store lists of pairs\n",
    "\n",
    "\n",
    "def association_lists():\n",
    "    pprint([\n",
    "        list(zip(keys, values1)),\n",
    "        list(zip(keys, values2)),\n",
    "        list(zip(keys, values3)),\n",
    "    ])\n",
    "association_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The association lists occupies more memory space keys are stored \n",
    "# 3 times instead of once, but we can do better (worse)!\n",
    "# Linear Search - let us speed it up by using separate chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(4670100726627187108, 'sarah', 'orange')],\n [(6263957734076381623, 'guido', 'blue'),\n  (4505871006362405169, 'barry', 'green'),\n  (8301609630502316535, 'rachel', 'yellow'),\n  (6421035295685486569, 'tim', 'red')]]\n"
     ]
    }
   ],
   "source": [
    "def separate_chaining(n):\n",
    "    buckets = [[] for _ in range(n)]\n",
    "    for pair in entries:\n",
    "        h, key, value = pair\n",
    "        i = h % n\n",
    "        buckets[i].append(pair)\n",
    "    pprint(buckets)\n",
    "    \n",
    "separate_chaining(2)  # That gives about 25% improved lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[],\n [(4505871006362405169, 'barry', 'green'), (6421035295685486569, 'tim', 'red')],\n [],\n [],\n [(4670100726627187108, 'sarah', 'orange')],\n [],\n [],\n [(6263957734076381623, 'guido', 'blue'),\n  (8301609630502316535, 'rachel', 'yellow')]]\n"
     ]
    }
   ],
   "source": [
    "separate_chaining(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(4505871006362405169, 'barry', 'green')],\n [(8301609630502316535, 'rachel', 'yellow')],\n [(6421035295685486569, 'tim', 'red')],\n [],\n [(6263957734076381623, 'guido', 'blue')],\n [(4670100726627187108, 'sarah', 'orange')],\n []]\n"
     ]
    }
   ],
   "source": [
    "# We can throw even more memory at it\n",
    "separate_chaining(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone gets found in just one probe!\n",
    "# What about memory several lists which need to be overallocated\n",
    "# with room to grow, some empty\n",
    "# To avoid overallocating memory for these lists we can create one\n",
    "# big table welcome to Open Addressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_addressing_linear(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (i + 1) % n\n",
    "        table[i] = (key, value)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rachel', 'yellow'),\n ('barry', 'green'),\n ('tim', 'red'),\n None,\n ('sarah', 'orange'),\n None,\n None,\n ('guido', 'blue')]\n"
     ]
    }
   ],
   "source": [
    "open_addressing_linear(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guido and Rachel wanted the same slot but rachel had to wrap around\n",
    "# This once in a while leads to catastrophic linear pile-up circa 1972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do better than fall back on linear probe lets use random\n",
    "# number generator congruential i = 5 * i + 1\n",
    "\n",
    "\n",
    "def open_addressing_multihash(n):\n",
    "    table = [None] * n\n",
    "    for h, key, value in entries:\n",
    "        perturb = h\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            print(f'{key!r} collided with {table[i][0]!r}')\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = (key, value)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rachel' collided with 'guido'\n'tim' collided with 'barry'\n'tim' collided with 'guido'\n'tim' collided with 'rachel'\n'tim' collided with 'barry'\n[None,\n ('barry', 'green'),\n None,\n ('rachel', 'yellow'),\n ('sarah', 'orange'),\n None,\n ('tim', 'red'),\n ('guido', 'blue')]\n"
     ]
    }
   ],
   "source": [
    "open_addressing_multihash(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performance slowed down but we avoid the catastrophic pileup\n",
    "\n",
    "If we use more space we avoid collisions which speeds up performance\n",
    "but use more memory. This implementation was in Python for quite a\n",
    "while with some size changes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compact_and_ordered(n):\n",
    "    table = [None] * n\n",
    "    for pos, entry, in enumerate(entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(entries)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6263957734076381623, 'guido', 'blue'),\n (4670100726627187108, 'sarah', 'orange'),\n (4505871006362405169, 'barry', 'green'),\n (8301609630502316535, 'rachel', 'yellow'),\n (6421035295685486569, 'tim', 'red')]\n[None, 2, None, 3, 1, None, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "compact_and_ordered(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the meantime there was key-sharing dict\n",
    "# This together with compact dict makes current 3.6 Python dict\n",
    "# implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_and_compact(n):\n",
    "    'Compact, ordered, and shared'\n",
    "    table = [None] * n\n",
    "    for pos, entry in enumerate(comb_entries):\n",
    "        h = perturb = entry[0]\n",
    "        i = h % n\n",
    "        while table[i] is not None:\n",
    "            i = (5 * i + perturb + 1) % n\n",
    "            perturb >>= 5\n",
    "        table[i] = pos\n",
    "    pprint(comb_entries)\n",
    "    pprint(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6263957734076381623, 'guido', 'blue', 'austin', 'apple'),\n (4670100726627187108, 'sarah', 'orange', 'dallas', 'banana'),\n (4505871006362405169, 'barry', 'green', 'tuscon', 'orange'),\n (8301609630502316535, 'rachel', 'yellow', 'reno', 'pear'),\n (6421035295685486569, 'tim', 'red', 'portland', 'peach')]\n[None, 2, None, 3, 1, None, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "shared_and_compact(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can make the dict more sparse without moving any ot the hash\n",
    "# key/ value entries. The additional sparsity costs only 8 bytes\n",
    "# and avoids all collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6263957734076381623, 'guido', 'blue', 'austin', 'apple'),\n (4670100726627187108, 'sarah', 'orange', 'dallas', 'banana'),\n (4505871006362405169, 'barry', 'green', 'tuscon', 'orange'),\n (8301609630502316535, 'rachel', 'yellow', 'reno', 'pear'),\n (6421035295685486569, 'tim', 'red', 'portland', 'peach')]\n[None,\n 2,\n None,\n None,\n 1,\n None,\n None,\n 0,\n None,\n 4,\n None,\n 3,\n None,\n None,\n None,\n None]\n"
     ]
    }
   ],
   "source": [
    "shared_and_compact(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}